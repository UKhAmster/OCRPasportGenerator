import os
import json
import torch
import argparse
import re
from PIL import Image
from transformers import DonutProcessor, VisionEncoderDecoderModel
from jiwer import cer


def evaluate(model_path, dataset_path, task_prompt):
    print(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {model_path}...")
    processor = DonutProcessor.from_pretrained(model_path)
    model = VisionEncoderDecoderModel.from_pretrained(model_path)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"‚ö° –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    model.to(device)
    model.eval()

    metadata_file = os.path.join(dataset_path, "metadata.jsonl")
    if not os.path.exists(metadata_file):
        raise FileNotFoundError(f"–§–∞–π–ª {metadata_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")

    with open(metadata_file, "r", encoding="utf-8") as f:
        metadata = [json.loads(line) for line in f]

    total_cer = 0.0
    exact_matches = 0
    total_images = len(metadata)

    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é {total_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")

    for idx, item in enumerate(metadata):
        image_path = os.path.join(dataset_path, item["file_name"])

        # –î–æ—Å—Ç–∞–µ–º –∏–¥–µ–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∏–∑ —Ç–≤–æ–µ–π –º–µ—Ç–∞–¥–∞—Ç—ã
        ground_truth_dict = json.loads(item["ground_truth"])["gt_parse"]

        try:
            image = Image.open(image_path).convert("RGB")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {image_path}: {e}")
            continue

        pixel_values = processor(image, return_tensors="pt").pixel_values.to(device)
        decoder_input_ids = processor.tokenizer(
            task_prompt, add_special_tokens=False, return_tensors="pt"
        ).input_ids.to(device)

        with torch.no_grad():
            outputs = model.generate(
                pixel_values,
                decoder_input_ids=decoder_input_ids,
                max_length=768,
                pad_token_id=processor.tokenizer.pad_token_id,
                eos_token_id=processor.tokenizer.eos_token_id,
                use_cache=True,
                bad_words_ids=[[processor.tokenizer.unk_token_id]],
                return_dict_in_generate=True,
            )

        # 1. –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä—É—é —Å—Ç—Ä–æ–∫—É —Å —Ç–µ–≥–∞–º–∏
        sequence = processor.batch_decode(outputs.sequences)[0]
        sequence = sequence.replace(processor.tokenizer.eos_token, "").replace(processor.tokenizer.pad_token, "")
        sequence = re.sub(r"^" + re.escape(task_prompt), "", sequence).strip()

        # 2. –ú–∞–≥–∏—è: –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º —Ç–µ–≥–∏ –º–æ–¥–µ–ª–∏ –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä—å!
        predicted_dict = processor.token2json(sequence)

        # 3. –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ (—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ —Å–ª–æ–≤–∞—Ä–µ–π –¥–ª—è CER)
        truth_str = json.dumps(ground_truth_dict, sort_keys=True, ensure_ascii=False)
        pred_str = json.dumps(predicted_dict, sort_keys=True, ensure_ascii=False)

        current_cer = cer(truth_str, pred_str)
        total_cer += current_cer

        if ground_truth_dict == predicted_dict:
            exact_matches += 1
            status = "‚úÖ –ò–î–ï–ê–õ–¨–ù–û"
        else:
            status = f"‚ùå –û–®–ò–ë–ö–ê (CER: {current_cer:.2f})"

        print(f"[{idx + 1}/{total_images}] {item['file_name']} | {status}")
        # –ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ —Å–º–æ—Ç—Ä–µ—Ç—å, –≥–¥–µ –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è, —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π —Å—Ç—Ä–æ–∫–∏ –Ω–∏–∂–µ:
        # if ground_truth_dict != predicted_dict:
        #     print(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: {truth_str}")
        #     print(f"   –ü–æ–ª—É—á–µ–Ω–æ:  {pred_str}")

    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    avg_cer = total_cer / total_images
    accuracy = (exact_matches / total_images) * 100

    print("\n" + "=" * 50)
    print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–ê–õ–ò–î–ê–¶–ò–ò ({dataset_path})")
    print("=" * 50)
    print(f"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")
    print(f"–ò–¥–µ–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (–¢–æ—á–Ω–æ—Å—Ç—å): {accuracy:.2f}%")
    print(f"–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –ø–æ —Å–∏–º–≤–æ–ª–∞–º (CER): {avg_cer:.4f} (–±–ª–∏–∂–µ –∫ 0 = –ª—É—á—à–µ)")
    print("=" * 50 + "\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ú–∞—Å—Å–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π")
    parser.add_argument('--type', type=str, choices=['passport', 'registration'], required=True)
    args = parser.parse_args()

    if args.type == "passport":
        evaluate("models_ready/donut_passport_v1", "dataset/val_passport", "<s_passport>")
    elif args.type == "registration":
        evaluate("models_ready/donut_registration_v1", "dataset/val_registration", "<s_registration>")