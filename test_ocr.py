import argparse
import torch
import re
from PIL import Image
from transformers import DonutProcessor, VisionEncoderDecoderModel


def recognize_document(image_path, doc_type):
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∏ –ø—Ä–æ–º–ø—Ç—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    if doc_type == "passport":
        model_path = "models_ready/donut_passport_v1"
        task_prompt = "<s_passport>"
    elif doc_type == "registration":
        model_path = "models_ready/donut_registration_v1"
        task_prompt = "<s_registration>"
    else:
        raise ValueError("–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'passport' –∏–ª–∏ 'registration'")

    print(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {model_path}...")
    try:
        processor = DonutProcessor.from_pretrained(model_path)
        model = VisionEncoderDecoderModel.from_pretrained(model_path)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ (–≤–æ–∑–º–æ–∂–Ω–æ, —É–∫–∞–∑–∞–Ω –Ω–µ–≤–µ—Ä–Ω—ã–π –ø—É—Ç—å): {e}")
        return

    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device.upper()}")
    model.to(device)
    model.eval()

    print(f"üñºÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_path}")
    try:
        image = Image.open(image_path).convert("RGB")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")
        return

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –¥–ª—è –º–æ–¥–µ–ª–∏
    pixel_values = processor(image, return_tensors="pt").pixel_values.to(device)

    # –ó–∞–¥–∞–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—ã–π —Ç–æ–∫–µ–Ω (–Ω–∞—à –ø—Ä–æ–º–ø—Ç)
    decoder_input_ids = processor.tokenizer(
        task_prompt, add_special_tokens=False, return_tensors="pt"
    ).input_ids.to(device)

    print("üß† –ù–µ–π—Ä–æ—Å–µ—Ç—å —á–∏—Ç–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç...")
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
    with torch.no_grad():
        outputs = model.generate(
            pixel_values,
            decoder_input_ids=decoder_input_ids,
            max_length=768,
            pad_token_id=processor.tokenizer.pad_token_id,
            eos_token_id=processor.tokenizer.eos_token_id,
            use_cache=True,
            bad_words_ids=[[processor.tokenizer.unk_token_id]],
            return_dict_in_generate=True,
        )

    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç
    sequence = processor.batch_decode(outputs.sequences)[0]

    # –û—á–∏—â–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–æ–∫–µ–Ω—ã (pad, eos –∏ —Å–∞–º —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç)
    sequence = sequence.replace(processor.tokenizer.eos_token, "").replace(processor.tokenizer.pad_token, "")
    sequence = re.sub(r"^" + re.escape(task_prompt), "", sequence).strip()

    print("\n" + "=" * 50)
    print("‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø:")
    print("=" * 50)
    print(sequence)
    print("=" * 50 + "\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OCR –º–æ–¥–µ–ª–µ–π (–ü–∞—Å–ø–æ—Ä—Ç / –ü—Ä–æ–ø–∏—Å–∫–∞)")
    parser.add_argument('--image', type=str, required=True, help='–ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ')
    parser.add_argument('--type', type=str, choices=['passport', 'registration'], required=True, help='–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞')

    args = parser.parse_args()
    recognize_document(args.image, args.type)